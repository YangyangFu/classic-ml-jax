{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emsemble Learning\n",
    "\n",
    "Reference:\n",
    "- element of statistical learning\n",
    "\n",
    "Two basic ensemble methods are:\n",
    "- Bagging: training a bunch of individual models in a parallel way. Each model is trained by a random subset of the data. The final predictions are averaged for regression or vote for classification.\n",
    "- Boosting: training a bunch of individual models in a sequential way. Each individual model learns from mistakes made by the previous model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "\n",
    "An typical boosting algorithm is AdaBoost (Adaptive Boosting). AdaBoost works by weighting the observations, putting more weight on difficult to classify instances and less on those already handled well. New classifiers are added sequentially that focus their training on the more difficult patterns.\n",
    "\n",
    "![adboost](./resources/imgs/adaboost.png)\n",
    "\n",
    "\n",
    "Another boosting algorithm is "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
