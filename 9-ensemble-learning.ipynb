{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emsemble Learning\n",
    "\n",
    "Reference:\n",
    "- element of statistical learning\n",
    "\n",
    "Two basic ensemble methods are:\n",
    "- Bagging: training a bunch of individual models in a parallel way. Each model is trained by a random subset of the data. The final predictions are averaged for regression or vote for classification.\n",
    "- Boosting: training a bunch of individual models in a sequential way. Each individual model learns from mistakes made by the previous model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bagging "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting\n",
    "\n",
    "\n",
    "An typical boosting algorithm is AdaBoost (Adaptive Boosting). AdaBoost works by weighting the observations, putting more weight on difficult to classify instances and less on those already handled well. New classifiers are added sequentially that focus their training on the more difficult patterns.\n",
    "\n",
    "![adboost](./resources/imgs/adaboost.png)\n",
    "\n",
    "\n",
    "AdaBoost is equivalent to a forward stagewise additive modeling using exponential loss.\n",
    "Since exponential loss is sensitive to outliers, AdaBoost has been empirically observed to be quite sensitive to noisy data and outliers.\n",
    "Typical classification loss function like cross-entroy, hinge loss, etc. are more robust to outliers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting Trees"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Trees\n",
    "\n",
    "![gbt](./resources/imgs/gradient-boosting-tree.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
