{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Linear Regression\n",
    "\n",
    "This is to reproduce chapter 3 of the book [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/people/cmbishop/#!prml-book) by Christopher M. Bishop.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import jax.scipy as jsp\n",
    "import numpy as np \n",
    "from scipy.stats import norm, multivariate_normal\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from basic.basis import Polynomial\n",
    "from basic.basis import Gaussian\n",
    "from basic.linear import BayesianLinearRegression\n",
    "\n",
    "np.random.seed(111)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likilyhood Function\n",
    "\n",
    "Suppose we are given a dataset $\\mathcal{D}=\\left\\{({\\mathbf x}_n, y_n)\\vert {\\mathbf x}_n \\in \\mathbb{R}^M, y_n\\in\\mathbb{R} \\right\\}_{n=1}^N$. Where each element $y_n$ is modelled as\n",
    "\n",
    "\n",
    "$$\n",
    "    y_n\\vert {\\mathbf x}_n \\sim \\mathcal{N}({\\mathbf w}^T{\\mathbf x}, \\sigma^2)\n",
    "$$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Distribution\n",
    "\n",
    "\n",
    "Furthermore, we we assign $\\mathbf w$ a *prior* distribution of the form ${\\mathbf w}\\sim\\mathcal{N}(\\boldsymbol\\mu_0, \\boldsymbol\\Sigma_0)$. Our goal is to find the *posterior* distribution ${\\mathbf w}\\vert \\mathcal{D}$, i.e.,\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p({\\mathbf w}\\vert \\mathcal{D}) &\\propto p({\\mathbf w})p(\\mathcal D\\vert {\\mathbf w})\\\\\n",
    "&= \\mathcal{N}({\\mathbf w}\\vert \\boldsymbol\\mu_0, \\boldsymbol\\Sigma_0) \\mathcal{N}({\\mathbf y} \\vert {\\mathbf X}{\\mathbf w}, \\sigma^2{\\mathbf I})\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "To find the posterior conjugate (a closed-form solution), note that\n",
    "\n",
    "$$\n",
    "    {\\mathbf z}^T{\\mathbf A}{\\mathbf z} - 2{\\mathbf z}^T{\\mathbf b} + c = ({\\mathbf z} - {\\mathbf A}^{-1}{\\mathbf b})^T{\\mathbf A}({\\mathbf z} - {\\mathbf A}^{-1}{\\mathbf b}) - {\\mathbf b}^T{\\mathbf A}^{-1}{\\mathbf b} + c\n",
    "$$\n",
    "\n",
    "Then,\n",
    "$$\n",
    "\\begin{align}\n",
    "    p({\\mathbf w}\\vert \\mathcal{D}) &\\propto \\exp\\left(-\\frac{1}{2} ({\\mathbf w} - \\boldsymbol\\mu_0)^T\\Sigma_0^{-1}({\\mathbf w} - \\boldsymbol\\mu_0) -\\frac{1}{2\\sigma^2} ({\\mathbf y} - {\\mathbf X w})^T({\\mathbf y} - {\\mathbf X w}) \\right)\\\\\n",
    "    &= \\exp\\left(-\\frac{1}{2}\\left( ({\\mathbf w} - \\boldsymbol\\mu_0)^T\\Sigma_0^{-1}({\\mathbf w} - \\boldsymbol\\mu_0) +\\frac{1}{\\sigma^2} ({\\mathbf y} - {\\mathbf X w})^T({\\mathbf y} - {\\mathbf X w})\\right) \\right)\\\\\n",
    "    &\\propto \\exp\\left(-\\frac{1}{2}\\left[{\\mathbf w}^T \\left(\\boldsymbol\\Sigma_0^{-1} + \\frac{1}{\\sigma^2}{\\mathbf X}^T{\\mathbf X}\\right) - 2{\\mathbf w}^T \\left(\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\mu_0 + \\frac{1}{\\sigma^2}{\\mathbf X}^T{\\mathbf y}\\right) \\right]\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This last expression reduces to\n",
    "\n",
    "$$\n",
    "    p({\\mathbf w}\\vert \\mathcal{D}) \\propto \\exp\\left(-\\frac{1}{2}({\\mathbf w} - {\\mathbf m}_N)^T {\\mathbf S}_N^{-1} ({\\mathbf w} - {\\mathbf m}_N)\\right)\n",
    "$$\n",
    "\n",
    "Where\n",
    "* ${\\mathbf S}_N^{-1} = \\boldsymbol\\Sigma_0^{-1} + \\frac{1}{\\sigma^2}{\\mathbf X}^T{\\mathbf X}$\n",
    "* ${\\mathbf m}_N = {\\mathbf S}_N \\left(\\boldsymbol\\Sigma_0^{-1}\\boldsymbol\\mu_0 + \\frac{1}{\\sigma^2}{\\mathbf X}^T{\\mathbf y}\\right)$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a bayesian perspective, there does not exist *a* vector of weights $\\mathbf w$; rather, $\\mathbf w$ is a random variable that we can sample from."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is to reproduce Figure 3.7 of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-09 16:31:05.757305: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:429] Could not create cudnn handle: CUDNN_STATUS_NOT_INITIALIZED\n",
      "2023-05-09 16:31:05.757341: E external/xla/xla/stream_executor/cuda/cuda_dnn.cc:438] Possibly insufficient driver version: 525.105.17\n"
     ]
    },
    {
     "ename": "XlaRuntimeError",
     "evalue": "FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39m# add polynomial features\u001b[39;00m\n\u001b[1;32m     19\u001b[0m basis \u001b[39m=\u001b[39m Polynomial()\n\u001b[0;32m---> 20\u001b[0m X_train \u001b[39m=\u001b[39m basis\u001b[39m.\u001b[39;49mtransform(x_train, degree\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     21\u001b[0m X \u001b[39m=\u001b[39m basis\u001b[39m.\u001b[39mtransform(x, degree\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[39m# bayesian linear regression\u001b[39;00m\n",
      "File \u001b[0;32m~/github/classic-ml-jax/basic/basis/polynomial.py:15\u001b[0m, in \u001b[0;36mPolynomial.transform\u001b[0;34m(self, x, degree)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtransform\u001b[39m(\u001b[39mself\u001b[39m, x, degree\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m):\n\u001b[1;32m      6\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"_summary_\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \n\u001b[1;32m      8\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m        _type_: _description_\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39;49marray([x\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mi \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m \u001b[39mrange\u001b[39;49m(degree \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)])\u001b[39m.\u001b[39;49mT\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/numpy/lax_numpy.py:541\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(a, axes)\u001b[0m\n\u001b[1;32m    539\u001b[0m axes_ \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mrange\u001b[39m(ndim(a))[::\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]) \u001b[39mif\u001b[39;00m axes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m axes\n\u001b[1;32m    540\u001b[0m axes_ \u001b[39m=\u001b[39m [_canonicalize_axis(i, ndim(a)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m axes_]\n\u001b[0;32m--> 541\u001b[0m \u001b[39mreturn\u001b[39;00m lax\u001b[39m.\u001b[39;49mtranspose(a, axes_)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/lax/lax.py:938\u001b[0m, in \u001b[0;36mtranspose\u001b[0;34m(operand, permutation)\u001b[0m\n\u001b[1;32m    936\u001b[0m   \u001b[39mreturn\u001b[39;00m type_cast(Array, operand)\n\u001b[1;32m    937\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 938\u001b[0m   \u001b[39mreturn\u001b[39;00m transpose_p\u001b[39m.\u001b[39;49mbind(operand, permutation\u001b[39m=\u001b[39;49mpermutation)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/core.py:360\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    358\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    359\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 360\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/core.py:363\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 363\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    364\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/core.py:817\u001b[0m, in \u001b[0;36mEvalTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_primitive\u001b[39m(\u001b[39mself\u001b[39m, primitive, tracers, params):\n\u001b[0;32m--> 817\u001b[0m   \u001b[39mreturn\u001b[39;00m primitive\u001b[39m.\u001b[39;49mimpl(\u001b[39m*\u001b[39;49mtracers, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/dispatch.py:117\u001b[0m, in \u001b[0;36mapply_primitive\u001b[0;34m(prim, *args, **params)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_src\u001b[39;00m \u001b[39mimport\u001b[39;00m pjit\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m   compiled_fun \u001b[39m=\u001b[39m xla_primitive_callable(prim, \u001b[39m*\u001b[39;49munsafe_map(arg_spec, args),\n\u001b[1;32m    118\u001b[0m                                         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams)\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m pxla\u001b[39m.\u001b[39mDeviceAssignmentMismatchError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m   fails, \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39margs\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/util.py:253\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    252\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m   \u001b[39mreturn\u001b[39;00m cached(config\u001b[39m.\u001b[39;49m_trace_context(), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/util.py:246\u001b[0m, in \u001b[0;36mcache.<locals>.wrap.<locals>.cached\u001b[0;34m(_, *args, **kwargs)\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mlru_cache(max_size)\n\u001b[1;32m    245\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcached\u001b[39m(_, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 246\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/dispatch.py:208\u001b[0m, in \u001b[0;36mxla_primitive_callable\u001b[0;34m(prim, *arg_specs, **params)\u001b[0m\n\u001b[1;32m    206\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[39mreturn\u001b[39;00m out,\n\u001b[0;32m--> 208\u001b[0m compiled \u001b[39m=\u001b[39m _xla_callable_uncached(lu\u001b[39m.\u001b[39;49mwrap_init(prim_fun), prim\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    209\u001b[0m                                   donated_invars, \u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49marg_specs)\n\u001b[1;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m prim\u001b[39m.\u001b[39mmultiple_results:\n\u001b[1;32m    211\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: compiled(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/dispatch.py:254\u001b[0m, in \u001b[0;36m_xla_callable_uncached\u001b[0;34m(fun, name, donated_invars, keep_unused, *arg_specs)\u001b[0m\n\u001b[1;32m    251\u001b[0m computation \u001b[39m=\u001b[39m sharded_lowering(fun, name, donated_invars, keep_unused,\n\u001b[1;32m    252\u001b[0m                                \u001b[39m*\u001b[39marg_specs, lowering_platform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    253\u001b[0m allow_prop \u001b[39m=\u001b[39m [\u001b[39mTrue\u001b[39;00m] \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(computation\u001b[39m.\u001b[39mcompile_args[\u001b[39m'\u001b[39m\u001b[39mglobal_out_avals\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m--> 254\u001b[0m \u001b[39mreturn\u001b[39;00m computation\u001b[39m.\u001b[39;49mcompile(_allow_propagation_to_outputs\u001b[39m=\u001b[39;49mallow_prop)\u001b[39m.\u001b[39munsafe_call\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:2816\u001b[0m, in \u001b[0;36mMeshComputation.compile\u001b[0;34m(self, _allow_propagation_to_outputs, _allow_compile_replicated)\u001b[0m\n\u001b[1;32m   2813\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m MeshExecutable\u001b[39m.\u001b[39mfrom_trivial_jaxpr(\n\u001b[1;32m   2814\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompile_args)\n\u001b[1;32m   2815\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2816\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable \u001b[39m=\u001b[39m UnloadedMeshExecutable\u001b[39m.\u001b[39;49mfrom_hlo(\n\u001b[1;32m   2817\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[1;32m   2818\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_hlo,\n\u001b[1;32m   2819\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcompile_args,\n\u001b[1;32m   2820\u001b[0m         _allow_propagation_to_outputs\u001b[39m=\u001b[39;49m_allow_propagation_to_outputs,\n\u001b[1;32m   2821\u001b[0m         _allow_compile_replicated\u001b[39m=\u001b[39;49m_allow_compile_replicated)\n\u001b[1;32m   2822\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_executable\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/interpreters/pxla.py:3028\u001b[0m, in \u001b[0;36mUnloadedMeshExecutable.from_hlo\u001b[0;34m(name, computation, mesh, global_in_avals, global_out_avals, in_shardings, out_shardings, spmd_lowering, tuple_args, auto_spmd_lowering, _allow_propagation_to_outputs, _allow_compile_replicated, unordered_effects, ordered_effects, host_callbacks, keepalive, kept_var_idx, backend, device_assignment, committed, pmap_nreps)\u001b[0m\n\u001b[1;32m   3024\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3025\u001b[0m   \u001b[39mwith\u001b[39;00m dispatch\u001b[39m.\u001b[39mlog_elapsed_time(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinished XLA compilation of \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3026\u001b[0m                                  \u001b[39m\"\u001b[39m\u001b[39min \u001b[39m\u001b[39m{elapsed_time}\u001b[39;00m\u001b[39m sec\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3027\u001b[0m                                  event\u001b[39m=\u001b[39mdispatch\u001b[39m.\u001b[39mBACKEND_COMPILE_EVENT):\n\u001b[0;32m-> 3028\u001b[0m     xla_executable \u001b[39m=\u001b[39m dispatch\u001b[39m.\u001b[39;49mcompile_or_get_cached(\n\u001b[1;32m   3029\u001b[0m         backend, computation, compile_options, host_callbacks)\n\u001b[1;32m   3031\u001b[0m   \u001b[39mif\u001b[39;00m auto_spmd_lowering:\n\u001b[1;32m   3032\u001b[0m     \u001b[39massert\u001b[39;00m mesh \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/dispatch.py:526\u001b[0m, in \u001b[0;36mcompile_or_get_cached\u001b[0;34m(backend, computation, compile_options, host_callbacks)\u001b[0m\n\u001b[1;32m    522\u001b[0m     _cache_write(serialized_computation, compile_time, module_name,\n\u001b[1;32m    523\u001b[0m                  compile_options, backend, compiled, host_callbacks)\n\u001b[1;32m    524\u001b[0m     \u001b[39mreturn\u001b[39;00m compiled\n\u001b[0;32m--> 526\u001b[0m \u001b[39mreturn\u001b[39;00m backend_compile(backend, serialized_computation, compile_options,\n\u001b[1;32m    527\u001b[0m                        host_callbacks)\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m~/miniconda3/envs/jax-0.4.8/lib/python3.10/site-packages/jax/_src/dispatch.py:471\u001b[0m, in \u001b[0;36mbackend_compile\u001b[0;34m(backend, built_c, options, host_callbacks)\u001b[0m\n\u001b[1;32m    466\u001b[0m   \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39mcompile(built_c, compile_options\u001b[39m=\u001b[39moptions,\n\u001b[1;32m    467\u001b[0m                          host_callbacks\u001b[39m=\u001b[39mhost_callbacks)\n\u001b[1;32m    468\u001b[0m \u001b[39m# Some backends don't have `host_callbacks` option yet\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[39m# TODO(sharadmv): remove this fallback when all backends allow `compile`\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39m# to take in `host_callbacks`\u001b[39;00m\n\u001b[0;32m--> 471\u001b[0m \u001b[39mreturn\u001b[39;00m backend\u001b[39m.\u001b[39;49mcompile(built_c, compile_options\u001b[39m=\u001b[39;49moptions)\n",
      "\u001b[0;31mXlaRuntimeError\u001b[0m: FAILED_PRECONDITION: DNN library initialization failed. Look at the errors above for more details."
     ]
    }
   ],
   "source": [
    "def create_toy_data(func, sample_size, std, domain=[0, 1]):\n",
    "    x = np.linspace(domain[0], domain[1], sample_size)\n",
    "    np.random.shuffle(x)\n",
    "    t = func(x) + np.random.normal(scale=std, size=x.shape)\n",
    "    return x, t\n",
    "\n",
    "def linear(x, a0, a1):\n",
    "    return a0 + a1 * x\n",
    "\n",
    "# data generation\n",
    "a0 = -0.3\n",
    "a1 = 0.5\n",
    "std = 0.2 \n",
    "beta = 1/std**2\n",
    "x_train, y_train = create_toy_data(lambda x: linear(x, a0, a1), 20, std, [-1, 1])\n",
    "x = np.linspace(-1, 1, 100)\n",
    "\n",
    "# add polynomial features\n",
    "basis = Polynomial()\n",
    "X_train = basis.transform(x_train, degree=1)\n",
    "X = basis.transform(x, degree=1)\n",
    "\n",
    "# bayesian linear regression\n",
    "bayesian = BayesianLinearRegression()\n",
    "\n",
    "# initialize prior distribution of w\n",
    "w0, w1 = np.meshgrid(\n",
    "    np.linspace(-1, 1, 100),\n",
    "    np.linspace(-1, 1, 100))\n",
    "w = np.array([w0, w1]).transpose(1, 2, 0)\n",
    "\n",
    "alpha = 2.0 # precision of noise\n",
    "w_mean, w_var = bayesian.init_w_prior(X_train, alpha)\n",
    "\n",
    "# plot\n",
    "for begin, end in [[0,0], [0, 1], [1, 2], [2, 3], [3, 20]]:\n",
    "\n",
    "    plt.subplot(1,3,1)\n",
    "    if end > 0:\n",
    "        # calculate maximum likelihood pdf of current incomming point\n",
    "        y_obs = y_train[end-1]\n",
    "        x_obs = X_train[end-1]\n",
    "        like_mean = w.reshape(-1,2) @ x_obs.T\n",
    "        like_std = std\n",
    "        likelihood = norm.pdf(y_obs, loc=like_mean, scale=like_std)\n",
    "        likelihood = likelihood.reshape(100,100)\n",
    "        plt.contour(w0, w1, likelihood)\n",
    "        w_mean, w_var = bayesian.fit(beta, w_mean, w_var, X_train[begin: end], y_train[begin: end])\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.xlabel(\"$w_0$\")\n",
    "    plt.ylabel(\"$w_1$\")\n",
    "         \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.scatter(-0.3, 0.5, s=200, marker=\"x\")\n",
    "    plt.contour(w0, w1, multivariate_normal.pdf(w, mean=w_mean, cov=w_var))\n",
    "    plt.gca().set_aspect('equal')\n",
    "    plt.title(\"prior/posterior\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.scatter(x_train[:end], y_train[:end], s=100, facecolor=\"none\", edgecolor=\"steelblue\", lw=1)\n",
    "    # sample 6 parameter pairs for plotting\n",
    "    w_samples = np.random.multivariate_normal(w_mean, w_var, size=6)\n",
    "    y_samples = X @ w_samples.T\n",
    "    plt.plot(x, y_samples, c=\"orange\")\n",
    "    plt.xlim(-1, 1)\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posterior Predictive Distribution\n",
    "\n",
    "Most times, we are not interested in the values of parameters $\\mathbf{w}$, but instead the prediction of a new data point $\\mathbf x$. To do so, we need to integrate out the parameters $\\mathbf w$ from the posterior distribution $p({\\mathbf w}\\vert \\mathcal{D})$.\n",
    "\n",
    "Before taking the sample, the uncertainty in $\\mathbf w$ is represented by the prior distribution $p(\\mathbf w)$.\n",
    "So for new data point $\\mathbf x$, averaging over $p(\\mathbf w)$ gives the `prior predictive distribution`:\n",
    "\n",
    "$$\n",
    "p(y|\\mathbf{x}) = \\int_{\\mathbf{w}} p(y| \\mathbf{x}, \\mathbf{w}) d\\mathbf{w} = \\int_{\\mathbf{w}} p(y|\\mathbf{x}, \\mathbf{w})p(\\mathbf{w})d\\mathbf{w} \n",
    "$$\n",
    "\n",
    "After taking the sample, the uncertainty in $\\mathbf w$ is represented by the posterior distribution $p({\\mathbf w}\\vert \\mathcal{D})$. \n",
    "So the `posterior prediction distribution` is:\n",
    "\n",
    "\\begin{align}\n",
    "p(y|\\mathbf{x}, \\mathcal{D}) &= \\int_{\\mathbf{w}} p(\\textit{y}, \\mathbf{w}|\\mathbf{x}, \\mathcal{D}) d\\mathbf{w} \\\\\n",
    "                        &= \\int_{\\mathbf{w}} p(\\textit{y}|\\mathbf{x}, \\mathbf{w}, \\mathcal{D})p(\\mathbf{w}|\\mathcal{D})d\\mathbf{w}\\\\\n",
    "                        &= \\int_{\\mathbf{w}} p(\\textit{y}|\\mathbf{x}, \\mathbf{w})p(\\mathbf{w}|\\mathcal{D})d\\mathbf{w} \\leftarrow \\text{new data is independent of samples}\\\\\n",
    "\\end{align}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convolution of two Gaussian distributions is another Gaussian distribution. So the posterior predictive distribution is also a Gaussian distribution:\n",
    "\n",
    "$$\n",
    "p(y|\\mathbf{x}, \\mathcal{D}) = \\mathcal{N}(y|\\mathbf{x}^T\\mathbf{m}_N, \\sigma^2 + \\mathbf{x}^T\\mathbf{S}_N\\mathbf{x})\n",
    "$$\n",
    "\n",
    "Where $\\mathbf{m}_N$ and $\\mathbf{S}_N$ are the posterior mean and covariance respectively."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code is to reproduce Figure 3.8 - Figure 3.9 of the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal(x):\n",
    "    return np.sin(2 * np.pi * x)\n",
    "\n",
    "samples = 25\n",
    "std = 0.25\n",
    "beta = 1/std**2\n",
    "\n",
    "x_train, y_train = create_toy_data(sinusoidal, samples, std)\n",
    "x_test = np.linspace(0, 1, 100)\n",
    "y_test = sinusoidal(x_test)\n",
    "\n",
    "feature = Gaussian()\n",
    "feature_mean, feature_var = np.linspace(0, 1, 9), 0.1\n",
    "X_train = feature.transform(x_train, feature_mean, feature_var)\n",
    "X_test = feature.transform(x_test, feature_mean, feature_var)\n",
    "\n",
    "model = BayesianLinearRegression()\n",
    "\n",
    "# initialize prior distribution of w\n",
    "w0, w1 = np.meshgrid(\n",
    "    np.linspace(-1, 1, 100),\n",
    "    np.linspace(-1, 1, 100))\n",
    "w = np.array([w0, w1]).transpose(1, 2, 0)\n",
    "\n",
    "alpha = 2.0 # precision of noise\n",
    "w_mean, w_var = model.init_w_prior(X_train, alpha)\n",
    "\n",
    "for begin, end in [[0, 1], [1, 2], [2, 4], [4, 8], [8, 25]]:\n",
    "    w_mean, w_var = model.fit(beta, w_mean, w_var, X_train[begin: end], y_train[begin: end])\n",
    "    y, y_std = model.predict(beta, w_mean, w_var, X_test)\n",
    "    \n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.scatter(x_train[:end], y_train[:end], s=100, facecolor=\"none\", edgecolor=\"steelblue\", lw=2, label=\"sample\")\n",
    "    plt.plot(x_test, y_test, label='$\\sin(2\\pi x)$')\n",
    "    plt.plot(x_test, y, label=\"mean\")\n",
    "    plt.fill_between(x_test, (y - y_std).reshape(-1), (y + y_std).reshape(-1), color=\"orange\", alpha=0.5, label='variance')\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.legend()\n",
    "    plt.title('Posterior Predictive Distribution')\n",
    "    \n",
    "    plt.subplot(1,2,2)\n",
    "    plt.scatter(x_train[:end], y_train[:end], s=100, facecolor=\"none\", edgecolor=\"steelblue\", lw=2, label=\"sample\")\n",
    "    plt.plot(x_test, y_test, label='$\\sin(2\\pi x)$')\n",
    "    # sample 6 parameter pairs for plotting\n",
    "    w_samples = np.random.multivariate_normal(w_mean, w_var, size=6)\n",
    "    y_samples = X_test @ w_samples.T\n",
    "    plt.plot(x_test, y_samples, c=\"orange\")\n",
    "    plt.xlim(0, 1)\n",
    "    plt.ylim(-2, 2)\n",
    "    plt.legend()\n",
    "    plt.title('Sample Functions')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax-0.4.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
